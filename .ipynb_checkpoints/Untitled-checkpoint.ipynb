{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotnine[all] in /Users/Sarah/anaconda3/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: descartes>=1.1.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (1.1.0)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.25.3)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.5.1)\n",
      "Requirement already satisfied: mizani>=0.6.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.6.0)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (1.16.4)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn; extra == \"all\" in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.22)\n",
      "Requirement already satisfied: scikit-misc; extra == \"all\" in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from pandas>=0.25.0->plotnine[all]) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from pandas>=0.25.0->plotnine[all]) (2019.1)\n",
      "Requirement already satisfied: six in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from patsy>=0.4.1->plotnine[all]) (1.12.0)\n",
      "Requirement already satisfied: palettable in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from mizani>=0.6.0->plotnine[all]) (3.3.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine[all]) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine[all]) (2.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine[all]) (0.10.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from scikit-learn; extra == \"all\"->plotnine[all]) (0.13.2)\n",
      "Requirement already satisfied: setuptools in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.1->plotnine[all]) (41.0.1)\n",
      "Requirement already satisfied: spacy in /Users/Sarah/anaconda3/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (0.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (41.0.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (1.16.4)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (0.23)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.32.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.6.16)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.5.1)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.16.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.0.8)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.0.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.32.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.5.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/Sarah/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "/Users/Sarah/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Requirement already up-to-date: textblob in /Users/Sarah/anaconda3/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from textblob) (3.4.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "[nltk_data] Downloading package brown to /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n",
      "Requirement already satisfied: vaderSentiment in /Users/Sarah/anaconda3/lib/python3.7/site-packages (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'plotnine[all]'\n",
    "!pip install spacy\n",
    "!python -m spacy download en\n",
    "!pip install -U textblob\n",
    "!python -m textblob.download_corpora\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import re\n",
    "from spacy.lang.en import English\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from nltk import ngrams\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset from Kaggle:\n",
    "tweets = pd.read_csv(\"https://raw.githubusercontent.com/SarahBuechner/DMML2019_Team_Google/master/Database/Tweets.csv\")\n",
    "AAL = pd.read_csv(\"https://raw.githubusercontent.com/SarahBuechner/DMML2019_Team_Google/master/Database/AAL.csv\")\n",
    "DAL = pd.read_csv(\"https://raw.githubusercontent.com/SarahBuechner/DMML2019_Team_Google/master/Database/DAL.csv\")\n",
    "LUV = pd.read_csv(\"https://raw.githubusercontent.com/SarahBuechner/DMML2019_Team_Google/master/Database/LUV.csv\")\n",
    "UAL = pd.read_csv(\"https://raw.githubusercontent.com/SarahBuechner/DMML2019_Team_Google/master/Database/UAL.csv\")\n",
    "# TO DO: Add the followers and verified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(tweet_to_be_classified): #here we use unfiltered tweets because TextBlob and Vader filters them \n",
    "    list_sentiments_textblob = []\n",
    "    list_sentiments_vader = []\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for element in tweet_to_be_classified:\n",
    "        # TextBlob\n",
    "        # TO DO: correct spelling \n",
    "        list_sentiments_textblob.append(TextBlob(element).sentiment)\n",
    "        # Vader\n",
    "        list_sentiments_vader.append(vader.polarity_scores(element))\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(list_sentiments_vader), pd.DataFrame(list_sentiments_textblob)], axis=1, sort=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the formula defined in the before code chunk in the whole dataset tweets.\n",
    "sentiment_table = sentiment_analysis(tweets[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the sentiment analysis in the dataframe tweets\n",
    "tweets[\"polarity_Vader\"] = sentiment_table[\"compound\"]\n",
    "tweets[\"polarity_Textblob\"] = sentiment_table[\"polarity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_string_conversion(polarity_values, new_column_name):\n",
    "  polarity_string=[]\n",
    "\n",
    "  for element in polarity_values:\n",
    "    if -1 <= element < 0:\n",
    "      polarity_string.append(\"negative\")\n",
    "    elif element == 0:\n",
    "      polarity_string.append(\"neutral\")\n",
    "    else: \n",
    "      polarity_string.append(\"positive\")\n",
    "\n",
    "  #Adding the string conversion to tweets dataframe\n",
    "  tweets[new_column_name] = polarity_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0            tweet_id airline_sentiment  \\\n",
      "0           0  570306133677760513           neutral   \n",
      "1           1  570301130888122368          positive   \n",
      "2           2  570301031407624196          negative   \n",
      "3           3  570300817074462722          negative   \n",
      "4           4  570300767074181121          negative   \n",
      "\n",
      "   airline_sentiment_confidence negativereason  negativereason_confidence  \\\n",
      "0                        1.0000            NaN                        NaN   \n",
      "1                        0.3486            NaN                     0.0000   \n",
      "2                        1.0000     Bad Flight                     0.7033   \n",
      "3                        1.0000     Can't Tell                     1.0000   \n",
      "4                        1.0000     Can't Tell                     0.6842   \n",
      "\n",
      "          airline airline_sentiment_gold      name negativereason_gold  ...  \\\n",
      "0  Virgin America                    NaN   cairdin                 NaN  ...   \n",
      "1  Virgin America                    NaN  jnardino                 NaN  ...   \n",
      "2  Virgin America                    NaN  jnardino                 NaN  ...   \n",
      "3  Virgin America                    NaN  jnardino                 NaN  ...   \n",
      "4  Virgin America                    NaN  jnardino                 NaN  ...   \n",
      "\n",
      "   tweet_coord              tweet_created tweet_location  \\\n",
      "0          NaN  2015-02-24 11:35:52 -0800            NaN   \n",
      "1          NaN  2015-02-24 11:15:59 -0800            NaN   \n",
      "2          NaN  2015-02-24 11:15:36 -0800            NaN   \n",
      "3          NaN  2015-02-24 11:14:45 -0800            NaN   \n",
      "4          NaN  2015-02-24 11:14:33 -0800            NaN   \n",
      "\n",
      "                user_timezone Followers Verified  polarity_Vader  \\\n",
      "0  Eastern Time (US & Canada)       517    False          0.0000   \n",
      "1  Pacific Time (US & Canada)      7714     True          0.0000   \n",
      "2  Pacific Time (US & Canada)      7714     True         -0.5984   \n",
      "3  Pacific Time (US & Canada)      7714     True         -0.5829   \n",
      "4  Pacific Time (US & Canada)      7714     True         -0.5945   \n",
      "\n",
      "   polarity_Textblob  polarity_Textblob_string  polarity_Vader_string  \n",
      "0           0.000000                   neutral                neutral  \n",
      "1           0.000000                   neutral                neutral  \n",
      "2           0.006250                  positive               negative  \n",
      "3          -0.350000                  negative               negative  \n",
      "4          -0.208333                  negative               negative  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Computing the conversion and storig to tweets\n",
    "polarity_string_conversion(tweets[\"polarity_Textblob\"], \"polarity_Textblob_string\")\n",
    "polarity_string_conversion(tweets[\"polarity_Vader\"], \"polarity_Vader_string\")\n",
    "print(tweets.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data to be compared with the original classification sentiment\n",
    "def classification_sentiment(method_used):\n",
    "  number_equal_sentiment = 0\n",
    "  for i in range(len(tweets[\"airline_sentiment\"])):\n",
    "    if tweets[\"airline_sentiment\"][i] == tweets[\"polarity_\"+ method_used +\"_string\"][i]:\n",
    "        number_equal_sentiment += 1\n",
    "  return (\"Using the method \"+ method_used + \": We estimated \" + str(number_equal_sentiment) + \" sentiments in the same way as the sentiments provided by the data set.\\n\" + \n",
    "          \"The \" + method_used + \" accuracy is equal to {:.2%}\".format(number_equal_sentiment/len(tweets[\"airline_sentiment\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the method Textblob: We estimated 5659 sentiments in the same way as the sentiments provided by the data set.\n",
      "The Textblob accuracy is equal to 46.14%\n",
      "Using the method Vader: We estimated 6721 sentiments in the same way as the sentiments provided by the data set.\n",
      "The Vader accuracy is equal to 54.80%\n"
     ]
    }
   ],
   "source": [
    "# Computing the accuracy for each method used\n",
    "print(classification_sentiment(\"Textblob\"))\n",
    "print(classification_sentiment(\"Vader\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision score when using TextBlob is of 0.51\n",
      "The precision score when using Vader is of 0.51\n",
      "The recall score when using TextBlob is of 0.56\n",
      "The recall score when using Vader is of 0.60\n"
     ]
    }
   ],
   "source": [
    "#Precision and recall scores\n",
    "\n",
    "#Precision \n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "y_true= tweets[\"airline_sentiment\"]\n",
    "\n",
    "#for TextBlob\n",
    "y_pred_t = tweets[\"polarity_Textblob_string\"]\n",
    "precision_score(y_true, y_pred_t, average = \"macro\")\n",
    "print(\"The precision score when using TextBlob is of {0:.2f}\".format(precision_score(y_true, y_pred_t, average = \"macro\")))\n",
    "\n",
    "#for Vader\n",
    "y_pred_v= tweets[\"polarity_Vader_string\"]\n",
    "tweets[\"polarity_Vader_string\"]\n",
    "precision_score(y_true, y_pred_v, average = \"macro\")\n",
    "print(\"The precision score when using Vader is of {0:.2f}\".format(precision_score(y_true, y_pred_t, average = \"macro\")))\n",
    "\n",
    "\n",
    "#Recall\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "#for TextBlob\n",
    "recall_score(y_true, y_pred_t, average = \"macro\")\n",
    "print(\"The recall score when using TextBlob is of {0:.2f}\".format(recall_score(y_true, y_pred_t, average = \"macro\")))\n",
    "\n",
    "#for Vader\n",
    "recall_score(y_true, y_pred_v, average = \"macro\")\n",
    "print(\"The recall score when using Vader is of {0:.2f}\".format(recall_score(y_true, y_pred_v, average=\"macro\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_t\n",
    "#y_pred_v\n",
    "#y_true\n",
    "# are non-numerical values\n",
    "\n",
    "#Label_encoder\n",
    "le = LabelEncoder()\n",
    "y_true_label_enc = le.fit_transform(y_true)\n",
    "y_pred_t_label_enc = le.fit_transform(y_pred_t)\n",
    "y_pred_v_label_enc = le.fit_transform(y_pred_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n",
      "[[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#One-hot_encoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#True value\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_true_label_enc = y_true_label_enc.reshape(len(y_true_label_enc), 1)\n",
    "y_true__onehot_enc = onehot_encoder.fit_transform(y_true_label_enc)\n",
    "print(y_true__onehot_enc)\n",
    "\n",
    "#Prediceted value with TextBlob\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_pred_t_label_enc = y_pred_t_label_enc.reshape(len(y_pred_t_label_enc), 1)\n",
    "y_pred_t_onehot_enc = onehot_encoder.fit_transform(y_pred_t_label_enc)\n",
    "print(y_pred_t_onehot_enc)\n",
    "\n",
    "#Prediceted value with Vader\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_pred_v_label_enc = y_pred_t_label_enc.reshape(len(y_pred_v_label_enc), 1)\n",
    "y_pred_v_onehot_enc = onehot_encoder.fit_transform(y_pred_v_label_enc)\n",
    "print(y_pred_v_onehot_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision-recall score with TextBlob prediction: 0.42\n",
      "Average precision-recall score with Vader prediction: 0.42\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "average_prec_recall_t = average_precision_score(y_pred_t_onehot_enc, y_true__onehot_enc)\n",
    "average_prec_recall_v = average_precision_score(y_pred_v_onehot_enc, y_true__onehot_enc)\n",
    "\n",
    "print('Average precision-recall score with TextBlob prediction: {0:.2f}'.format(average_prec_recall_t))\n",
    "print('Average precision-recall score with Vader prediction: {0:.2f}'.format(average_prec_recall_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9812, 3)\n",
      "(2453, 3)\n",
      "(9812, 3)\n",
      "(2453, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X = y_pred_t_onehot_enc\n",
    "y = y_true__onehot_enc\n",
    "\n",
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)\n",
    "\n",
    "print((X_train).shape)\n",
    "print((X_test).shape)\n",
    "print((y_train).shape)\n",
    "print((y_test).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf = OneVsRestClassifier(LinearSVC()) #not working with only clf = svm.LinearSVC() > bad input shape error\n",
    "clf.fit(X_train, y_train)\n",
    "y_score = clf.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "OneVsRestClassifier should be a binary classifer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8c1158b7bd44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_precision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m disp.ax_.set_title('2-class Precision-Recall curve: '\n\u001b[1;32m      7\u001b[0m                    'AP={0:0.2f}'.format(average_precision))\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_plot/precision_recall_curve.py\u001b[0m in \u001b[0;36mplot_precision_recall_curve\u001b[0;34m(estimator, X, y, sample_weight, response_method, name, ax, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: OneVsRestClassifier should be a binary classifer"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "disp = plot_precision_recall_curve(clf, X_test, y_test)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noisy features\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X = y_pred_t_onehot_enc\n",
    "y = y_true__onehot_enc\n",
    "\n",
    "# Split into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)\n",
    "\n",
    "# Run classifier\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "average_precision = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_test[:, i],\n",
    "                                                        y_score[:, i])\n",
    "    average_precision[i] = average_precision_score(y_test[:, i], y_score[:, i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "precision[\"micro\"], recall[\"micro\"], _ = precision_recall_curve(y_test.ravel(),\n",
    "    y_score.ravel())\n",
    "average_precision[\"micro\"] = average_precision_score(y_test, y_score,\n",
    "                                                     average=\"micro\")\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.clf()\n",
    "plt.plot(recall[0], precision[0], label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall example: AUC={0:0.2f}'.format(average_precision[0]))\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "\n",
    "# Plot Precision-Recall curve for each class\n",
    "plt.clf()\n",
    "plt.plot(recall[\"micro\"], precision[\"micro\"],\n",
    "         label='micro-average Precision-recall curve (area = {0:0.2f})'\n",
    "               ''.format(average_precision[\"micro\"]))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(recall[i], precision[i],\n",
    "             label='Precision-recall curve of class {0} (area = {1:0.2f})'\n",
    "                   ''.format(i, average_precision[i]))\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Extension of Precision-Recall curve to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
