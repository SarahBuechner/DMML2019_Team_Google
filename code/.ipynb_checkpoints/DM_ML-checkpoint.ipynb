{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "GAsfGNL_TtF4",
    "outputId": "e25d4a34-7d2c-4e49-dfb4-7c3e0c61a163",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotnine[all] in /Users/Sarah/anaconda3/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: matplotlib>=3.1.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (1.3.0)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.5.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.10.0)\n",
      "Requirement already satisfied: pandas>=0.25.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.25.3)\n",
      "Requirement already satisfied: descartes>=1.1.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (1.1.0)\n",
      "Requirement already satisfied: mizani>=0.6.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (1.16.4)\n",
      "Requirement already satisfied: scikit-learn; extra == \"all\" in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.22)\n",
      "Requirement already satisfied: scikit-misc; extra == \"all\" in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from plotnine[all]) (0.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine[all]) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine[all]) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine[all]) (2.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from matplotlib>=3.1.1->plotnine[all]) (0.10.0)\n",
      "Requirement already satisfied: six in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from patsy>=0.4.1->plotnine[all]) (1.12.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from pandas>=0.25.0->plotnine[all]) (2019.1)\n",
      "Requirement already satisfied: palettable in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from mizani>=0.6.0->plotnine[all]) (3.3.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from scikit-learn; extra == \"all\"->plotnine[all]) (0.13.2)\n",
      "Requirement already satisfied: setuptools in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=3.1.1->plotnine[all]) (41.0.1)\n",
      "Requirement already satisfied: spacy in /Users/Sarah/anaconda3/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: setuptools in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (41.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (0.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (1.16.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (0.23)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.6.16)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.32.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.5.1)\n",
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from en_core_web_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.2.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.16.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.0.8)\n",
      "Requirement already satisfied: setuptools in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (41.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.3.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.23)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.32.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (0.5.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/Sarah/anaconda3/lib/python3.7/site-packages/en_core_web_sm -->\n",
      "/Users/Sarah/anaconda3/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Requirement already up-to-date: textblob in /Users/Sarah/anaconda3/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from textblob) (3.4.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /Users/Sarah/anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "[nltk_data] Downloading package brown to /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/Sarah/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Finished.\n",
      "Requirement already satisfied: vaderSentiment in /Users/Sarah/anaconda3/lib/python3.7/site-packages (3.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'plotnine[all]'\n",
    "!pip install spacy\n",
    "!python -m spacy download en\n",
    "!pip install -U textblob\n",
    "!python -m textblob.download_corpora\n",
    "!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0yCC2k-pUK38"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-99a2b0427382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0men\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnglish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPrecisionRecallCurve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvaderSentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvaderSentiment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import itertools\n",
    "import nltk\n",
    "\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from plotnine import *\n",
    "from spacy.lang.en import English\n",
    "from textblob import TextBlob\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nltk import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from yellowbrick.draw import manual_legend\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GxzHCVSoHvpo"
   },
   "source": [
    "## DATA MINING AND MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9apdauaTeQ7"
   },
   "outputs": [],
   "source": [
    "# The dataset from Kaggle:\n",
    "tweets = pd.read_csv(\"https://raw.githubusercontent.com/SarahBuechner/DMML2019_Team_Google/master/data/Tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Rj9wyKOwFFR"
   },
   "source": [
    "### The structure of DM & ML\n",
    "- 1.0) Try our model classification -> Expected bad accuracy **TO DO**\n",
    "- 1.1) Classify the tweets using TextBlob and Vader -> Accuracy 55%\n",
    "- 1.2) Understand why those methods classified wrongly the tweets and create the **Major Matrix** to store the wrong classified tweets\n",
    "- 1.3) Reclassified the tweets in the **Major Matrix** -> Expected better accuracy\n",
    "- 1.4) Implement the whole process with train and test validation\n",
    "- 1.5) If it is possible to validate the model with another dataset\n",
    "- 1.6) Business model: Sort the tweets that have to be replied firstly: \n",
    "   - (i) Based on polarity (Vader index)\n",
    "   - (ii) Based on verified account\n",
    "   - (iii) Based on # number of followers\n",
    "- 1.7) Vader and TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VVbN7WpfYx4N"
   },
   "source": [
    "### 1) Using the methods seen in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lPu6LpS0rMB3"
   },
   "source": [
    "Function tokenization_tweets\n",
    "\n",
    "The function **`tokenization_tweets`** allows the user to *tokenize* the tweet removing the *noise*:\n",
    "\n",
    "**Tokens removed**:\n",
    "*   Stop words\n",
    "*   Punctuation\n",
    "*   Tokens with less than 3 characters\n",
    "*   Tokens containing a non alphabet character (i.e. \"/\", \"@\", etc.)\n",
    "*   Empty tokens (not implemented)\n",
    "\n",
    "Then the trailing whitespaces are removed from the token using `strip()` and finally is converted to a lowercase word using `lower()`. If after removing the not desired tokens the `filtered_tweet` is empty, we do not include it into the `list_filtered_tweets`.\n",
    "\n",
    "**Arguments**: \n",
    "*   `list_tweets`: array containing the tweets. \n",
    "*   `number_observations`: how many observations we want to treat (it will be removed in the future but now is usefull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H8n5i22IsWjI"
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def tokenization_tweets(tweet):\n",
    "    only_letters = re.sub(\"[^a-zA-Z]\", \" \",tweet) \n",
    "    tokens = nltk.word_tokenize(only_letters)[2:]\n",
    "    lower_case = [l.lower() for l in tokens]\n",
    "    filtered_result = list(filter(lambda l: l not in STOPWORDS, lower_case))\n",
    "    lemmas = [wordnet_lemmatizer.lemmatize(t) for t in filtered_result]\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCSym1VKt54B"
   },
   "outputs": [],
   "source": [
    "# Saving tokens for each tweets\n",
    "tweets['tokenized_tweet'] = tweets.text.apply(tokenization_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iCdMyOyc-Ozf"
   },
   "outputs": [],
   "source": [
    "# Saving tokens for each tweet as a string\n",
    "tweets['tokens_string'] = tweets.tokenized_tweet.apply(lambda token:' '.join(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0G3JPrnmF73"
   },
   "outputs": [],
   "source": [
    "X = tweets['tokens_string'] # the features we want to analyze, we can play with others too\n",
    "y = tweets['airline_sentiment'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSWqRFHznxoG"
   },
   "outputs": [],
   "source": [
    "# Converting the tokens using CountVectorizer\n",
    "v = CountVectorizer(analyzer = \"word\")\n",
    "\n",
    "X_train = v.fit_transform(X_train)\n",
    "X_test = v.transform(X_test)\n",
    "\n",
    "# Converting the sentiment into a numerical class\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5b3L8aR3NOgo"
   },
   "source": [
    "#### 1.1) Logistic Regression Classifier\n",
    "> **Count Vectorizer:** The most straightforward one, it counts the number of times a token shows up in the document and uses this value as its weight.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qOH1q-M2XRw2"
   },
   "source": [
    "#### 1.2) K Neighbors Classifier\n",
    "> **KNeighborsClassifier:** classifies the tweets into different classes according to the k nearest neighbors. \n",
    "We used uniform weights, meaning that all points in each neighborhood are weighted equally.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-61iGdKXZdT"
   },
   "source": [
    "#### 1.3) Decision Tree Classifier\n",
    "> **DecisionTreeClassifier:** splits the tweets into different classes according to specific criteria.<br/>\n",
    "Here we use the following default parameters: <br/>\n",
    "- criterion='gini', <br/> \n",
    "To measure the quality of a split we used the Gini impurity. \n",
    "Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. \n",
    "- splitter='best',<br/>\n",
    "To choose the split at each node we chose the best split algorithm. \n",
    "- max_depth=None,<br/>\n",
    "We did not define any maximum depth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIcy3dF2Xgy5"
   },
   "source": [
    "#### 1.4) Random Forest Classifier\n",
    "> **RandomForestClassifier:** fits decision trees on randomly selected sub-samples of the dataset, gets prediction from each tree and selects the best solution (improve accurary and control over-fitting) by averaging.\n",
    "The sub-sample size is always the same as the original\n",
    "input sample size. Here we chose to draw the samples with replacement as we set`bootstrap=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DwmBm8CZdEEw"
   },
   "outputs": [],
   "source": [
    "# Creating the classifiers\n",
    "classifiers = [\n",
    "    LogisticRegression(C = 0.0001, solver = 'liblinear', max_iter = 200),\n",
    "    KNeighborsClassifier(3),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators = 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "AddWJdi-glx8",
    "outputId": "dff66b43-3dec-43db-f929-ce9ad15d182a"
   },
   "outputs": [],
   "source": [
    "# Computing the accuracy for each classifier\n",
    "accuracies=[]\n",
    "models=[]\n",
    "\n",
    "for classifier in classifiers:\n",
    "  fit = classifier.fit(X_train, y_train)\n",
    "  pred = fit.predict(X_test)\n",
    "  accuracy = accuracy_score(pred, y_test)\n",
    "  print('Accuracy of '+ classifier.__class__.__name__ + ' is ' + str(accuracy)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "mNZyv5gO-vCQ",
    "outputId": "897f6437-fc10-4b76-dc0b-556697f97346"
   },
   "outputs": [],
   "source": [
    "for classifier in classifiers:  \n",
    "  viz = PrecisionRecallCurve(classifier, fill_area=False, ap_score=False)\n",
    "  viz.fit(X_train, y_train)\n",
    "  viz.score(X_test, y_test)\n",
    "  manual_legend(viz, ('LogisticRegression', 'KNeighborsClassifier', 'DecisionTreeClassifier', 'RandomForestClassifier'), ('m', 'b', 'r', 'g'), frameon=True, loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DbH74JejC37v"
   },
   "source": [
    "### 2) Classification using TextBlob and Vader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BOOG3VbnX7EU"
   },
   "source": [
    "#### 2.1) Function tweet_sentiment_analysis\n",
    "The function **`tweet_sentiment_analysis`** computes the sentiment analysis of each tweet using **TextBlob** (`polarity` and `subjectivity`) and using **Vader** (`neg`, `neu`, `pos` and `compound`)\n",
    "\n",
    "> **Polarity** : Polarity is a float value within the range `[-1.0 to 1.0]` where 0 indicates neutral, +1 indicates a very positive sentiment and -1 represents a very negative sentiment.\n",
    "\n",
    "> **Subjectivity**: Subjectivity is a float value within the range `[0.0 to 1.0]` where 0.0 is very objective and 1.0 is very subjective. \n",
    "\n",
    "> **Compound**: Similar to polarity in Textblob, is a float value within the range `[0.0 to 1.0]` where 0.0 is very objective and 1.0 is very subjective. A key difference however, is that Vader was designed with a focus on social media texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jRVDmmpqCv85"
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis(tweet_to_be_classified): #here we use unfiltered tweets because TextBlob and Vader filters them \n",
    "    list_sentiments_textblob = []\n",
    "    list_sentiments_vader = []\n",
    "    vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for element in tweet_to_be_classified:\n",
    "        list_sentiments_textblob.append(TextBlob(element).sentiment) # TextBlob \n",
    "        list_sentiments_vader.append(vader.polarity_scores(element)) # Vader\n",
    "\n",
    "    df = pd.concat([pd.DataFrame(list_sentiments_vader), pd.DataFrame(list_sentiments_textblob)], axis=1, sort=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtD_suchFZlx"
   },
   "outputs": [],
   "source": [
    "# Applying the formula sentiment analysis for the whole dataset.\n",
    "sentiment_table = sentiment_analysis(tweets[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFyl6Rs20czp"
   },
   "outputs": [],
   "source": [
    "# Storing the sentiment analysis in the dataframe tweets\n",
    "tweets[\"polarity_Vader\"] = sentiment_table[\"compound\"]\n",
    "tweets[\"polarity_Textblob\"] = sentiment_table[\"polarity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1J0nK-FfFh5s"
   },
   "source": [
    "#### 2.2) Function polarity_string_conversion\n",
    "\n",
    "For technical purposes it is needed to convert the sentiment data we found into strings.\n",
    "Such that:\n",
    "> **Polarity ϵ {-1, 1}**\n",
    "* `polarity < 0`: the tweet is negative <br>\n",
    "* `polarity == 0`: the tweet is neutral <br>\n",
    "* `polarity <= 1`: the tweet is positive <br>\n",
    "\n",
    "$$ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ Where \\ p \\in (-1, 1)$$\n",
    "\n",
    "\n",
    "$$\n",
    "T(p) = \\left\\{\n",
    "        \\begin{array}{ll}\n",
    "            negative & if \\quad p < 0 \\\\\n",
    "            neutral & if \\quad p = 0 \\\\\n",
    "            positive & if \\quad p > 0 \\\\\n",
    "        \\end{array}\n",
    "    \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UIF7FArfu5eL"
   },
   "outputs": [],
   "source": [
    "def polarity_string_conversion(polarity_values, new_column_name):\n",
    "  polarity_string=[]\n",
    "\n",
    "  for element in polarity_values:\n",
    "    if element < 0:\n",
    "      polarity_string.append(\"negative\")\n",
    "    elif element == 0:\n",
    "      polarity_string.append(\"neutral\")\n",
    "    else: \n",
    "      polarity_string.append(\"positive\")\n",
    "\n",
    "  #Adding the string conversion to tweets dataframe\n",
    "  tweets[new_column_name] = polarity_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "7faSfUT5v2Jr",
    "outputId": "4f788127-9092-4f07-bf48-cd0d776659c1"
   },
   "outputs": [],
   "source": [
    "# Computing the conversion and storing to tweets dataframe for both methods\n",
    "polarity_string_conversion(tweets[\"polarity_Textblob\"], \"polarity_Textblob_string\")\n",
    "polarity_string_conversion(tweets[\"polarity_Vader\"], \"polarity_Vader_string\")\n",
    "print(tweets.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJWE5s0ZzlVY"
   },
   "source": [
    "#### 2.3) Function classification_sentiment_accuracy\n",
    "\n",
    "The below formula enables to compute the accuracy of each method. The argument is the method as a string: `('Textblob', 'Vader')`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9SdjkVZG3tQ"
   },
   "outputs": [],
   "source": [
    "# Preparing the data to be compared with the original classification sentiment\n",
    "def classification_sentiment_accuracy(method_used):\n",
    "  number_equal_sentiment = 0\n",
    "  for i in range(len(tweets[\"airline_sentiment\"])):\n",
    "    if tweets[\"airline_sentiment\"][i] == tweets[\"polarity_\"+ method_used +\"_string\"][i]:\n",
    "        number_equal_sentiment += 1\n",
    "  return (\"Using the method \"+ method_used + \": We estimated \" + str(number_equal_sentiment) + \" sentiments in the same way as the sentiments provided by the data set.\\n\" + \n",
    "          \"The \" + method_used + \" accuracy is equal to {:.2%}\".format(number_equal_sentiment/len(tweets[\"airline_sentiment\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "cPtzuZ9oyuxL",
    "outputId": "8105179f-7e83-49af-c263-2e9a928ad979"
   },
   "outputs": [],
   "source": [
    "# Printing the accuracy for each method used\n",
    "print(classification_sentiment_accuracy(\"Textblob\"))\n",
    "print(classification_sentiment_accuracy(\"Vader\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vNZipMdN0dz-"
   },
   "source": [
    "### 3) Why some tweets were classified wrongly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nSpcy5a1YOsS"
   },
   "source": [
    "#### 3.1) Confusion Matrix\n",
    "First of all, we show how the errors are distributed. The Confusion matrix does a good work for that purpose. We have 6 types of errors since there are 3 classes.\n",
    "\n",
    "**Note:** Notice that the values showed in below are expressed as a percentage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "ULY-OaAlZDUs",
    "outputId": "9aff0d48-3b53-43cb-c67a-e78c5afd2ecb"
   },
   "outputs": [],
   "source": [
    "# Computing the Confusion Matrix of each method\n",
    "print(confusion_matrix(tweets[\"airline_sentiment\"], tweets[\"polarity_Textblob_string\"])/len(tweets[\"airline_sentiment\"]), \"\\n\")\n",
    "print(confusion_matrix(tweets[\"airline_sentiment\"], tweets[\"polarity_Vader_string\"])/len(tweets[\"airline_sentiment\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KwlSA50GJWWc"
   },
   "source": [
    "####3.2) Confusion Matrix plot\n",
    "TO DO: explain it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "colab_type": "code",
    "id": "w781EUdMapoT",
    "outputId": "9d0a1f7a-962f-4c11-88e1-a38761f9827c"
   },
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX PLOT\n",
    "def plot_confusion_matrix(method, cm, classes, normalize=False, cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylim([-0.5, 2.5])\n",
    "    plt.title(method + \" Confusion Matrix\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "methods = [\"Vader\", \"Textblob\"]\n",
    "\n",
    "for method in methods:\n",
    "  target = tweets[\"airline_sentiment\"]\n",
    "  predicted_TextBlob = tweets[\"polarity_\"+ method +\"_string\"]\n",
    "\n",
    "  class_names = unique_labels(target, predicted_TextBlob)\n",
    "\n",
    "  # Computing the confusion matrix\n",
    "  cnf_matrix = confusion_matrix(target, predicted_TextBlob)\n",
    "  np.set_printoptions(precision=2)\n",
    "\n",
    "  # Ploting non-normalized confusion matrix\n",
    "  fig, ax = plt.subplots(figsize=(7,5))\n",
    "  plot_confusion_matrix(method, cnf_matrix, classes=class_names)\n",
    "  fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0p321jsVnF6-"
   },
   "source": [
    "#### 3.3) Precision & Recall Scores\n",
    "**Precision Score** shows the ability of a classification model to return only relevant instances <br>\n",
    "Precision Score = TP /TP + FP <br>\n",
    "<br>\n",
    "**Recall Score** shows the ability of a classification model to identify all relevant instances <br>\n",
    "Precision Score = TP /TP + FN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TlYvHfjAJ8Xs"
   },
   "source": [
    "#### 3.4) Scatter classification plot\n",
    "TO DO: explain it\n",
    " - **Color:** Actual value `tweets[\"airline_sentiment\"]`\n",
    " - **Size:** Total number of followers `tweets[\"Followers\"]`\n",
    " - **X axes:** polarity computed by Textblob `tweets[\"polarity_Textblob\"]`\n",
    " - **Y axes:**  = polarity computed by Vader `tweets[\"polarity_Vader\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "colab_type": "code",
    "id": "GI49gLm24Ymi",
    "outputId": "b11895c0-c271-488c-9b26-8e62297752a9"
   },
   "outputs": [],
   "source": [
    "# Another way to visualize the error predicted by both methods, size dots = # followers\n",
    "X = tweets[\"polarity_Textblob\"]\n",
    "y = tweets[\"polarity_Vader\"]\n",
    "followers = tweets[\"Followers\"]\n",
    "s = []\n",
    "for t in followers:\n",
    "  if t < 100:\n",
    "    s.append(1)\n",
    "  elif t < 500:\n",
    "    s.append(5)\n",
    "  elif t < 1500:\n",
    "    s.append(8)\n",
    "  elif t < 5000:\n",
    "    s.append(20)\n",
    "  else:\n",
    "    s.append(200)\n",
    "\n",
    "def scatter_plot(lst):\n",
    "    cols=[]\n",
    "    for l in lst:\n",
    "        if l=='negative':\n",
    "            cols.append('red')\n",
    "        elif l=='neutral':\n",
    "            cols.append('blue')\n",
    "        else:\n",
    "            cols.append('green')\n",
    "    return cols\n",
    "\n",
    "colors = scatter_plot(tweets[\"airline_sentiment\"])\n",
    "size = 5000\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(X[:size], y[:size], c = colors[:size], edgecolors='k', s = s[:size])\n",
    "plt.ylabel('VADER Polarity')\n",
    "plt.xlabel('TEXTBLOB Polarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NyxKpKAjMnOh"
   },
   "source": [
    "#### 3.5) The Major Matrix\n",
    "The **Major Matrix** enables to store all the tweets wronlgy classified in the first attempt.\n",
    "\n",
    "$$ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ Predicted \\ \\ Value $$\n",
    "$$ Actual \\ \\ Value \\  \\begin{pmatrix}\n",
    "0 & (5) \\ a_{pos}\\_p_{neu} & (2) \\ a_{pos}\\_p_{neg}\\\\\n",
    "(3) \\ a_{neu}\\_p_{pos} & 0 & (6) \\ a_{neu}\\_p_{neg}\\\\\n",
    "(1) \\ a_{neg}\\_p_{pos} & (4) \\ a_{neg}\\_p_{neu} & 0\\\\\n",
    "\\end{pmatrix}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xv5XoD7GPDGh"
   },
   "outputs": [],
   "source": [
    "# Defining the predicted and actual values\n",
    "pred_TBlob = tweets[\"polarity_Textblob\"]\n",
    "pred_Vlder = tweets[\"polarity_Vader\"]\n",
    "act_sent = tweets[[\"airline_sentiment\",\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9tXg-4GPSKr3"
   },
   "outputs": [],
   "source": [
    "# Detecting and storing the incorrect tweets\n",
    "def incorrect_predicted_tweets(actual_sentiment, predicted_sentiment):\n",
    "  df = []\n",
    "  for i in range(len(pred_Vlder)):\n",
    "    if predicted_sentiment == \"positive\":\n",
    "        if pred_Vlder[i] > 0 and act_sent.iloc[i,0] == actual_sentiment:\n",
    "          df.append(act_sent.iloc[i,1])  \n",
    "    elif predicted_sentiment == \"neutral\":\n",
    "        if pred_Vlder[i]  == 0 and act_sent.iloc[i,0] == actual_sentiment:\n",
    "          df.append(act_sent.iloc[i,1]) \n",
    "    else:   \n",
    "      if pred_Vlder[i] < 0 and act_sent.iloc[i,0] == actual_sentiment:\n",
    "        df.append(act_sent.iloc[i,1])\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GFRV90DTPOxL"
   },
   "outputs": [],
   "source": [
    "# Applying the incorrect_predicted_tweets formula for each type of error:\n",
    "actual_predicted = {\"aneu_ppos\": [\"neutral\", \"positive\"], \n",
    "                    \"aneg_pneu\" : [\"negative\", \"neutral\"], \n",
    "                    \"apos_pneu\" : [\"positive\", \"neutral\"], \n",
    "                    \"aneu_pneg\" : [\"neutral\", \"negative\"], \n",
    "                    \"aneg_ppos\" : [\"negative\", \"positive\"], \n",
    "                    \"apos_pneg\" : [\"positive\", \"negative\"]}\n",
    "\n",
    "wrong_tweets = {}\n",
    "for key in actual_predicted:\n",
    "  wrong_tweets[key] = incorrect_predicted_tweets(actual_predicted[key][0],actual_predicted[key][1])\n",
    "\n",
    "# Creating a DataFrame for each tweet wrongly classified\n",
    "df_wrong_tweets = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in wrong_tweets.items() ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T3EwFZCiPUJF"
   },
   "source": [
    "If the reader wants to verify if the **`incorrect_predicted_tweets`** where correctly stored in the **Major Matrix** he can run the code below:\n",
    "```python\n",
    "print(len(df_wrong_tweets[\"apos_pneg\"].dropna())) \n",
    "print(len(df_wrong_tweets[\"aneu_pneg\"].dropna()))\n",
    "print(len(df_wrong_tweets[\"apos_pneu\"].dropna()))\n",
    "print(len(df_wrong_tweets[\"aneg_pneu\"].dropna()))\n",
    "print(len(df_wrong_tweets[\"aneu_ppos\"].dropna()))\n",
    "print(len(df_wrong_tweets[\"aneg_ppos\"].dropna()))\n",
    "```\n",
    "\n",
    "You will find that the lenght of each type of error is equal to the confusion matrix when is not normalized. For instance, The first line of code is equal to 78, which corresponds a **True value = positve** and **Predicted value = negative**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fO05YOwmQIQw"
   },
   "source": [
    "#### 3.6) The error types "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0aimKxx9lvrK"
   },
   "source": [
    "###### Error (1): *apos_pneg*\n",
    "Tweets where the actual value is positive but Vader classified as negative:\n",
    "\n",
    "> **Green dots ubicated in y < 0 in the Scatter calssification plot** \n",
    "\n",
    "**Spoiler!** TextBlob does not distinguish sarcasm or irony and have serious problems when have to classify *ambiguous words* such as \"killed\".\n",
    "\n",
    "*Other examples:*\n",
    "* less painful\n",
    "* obsessed with\n",
    "* it was absurd\n",
    "* freaked me out\n",
    "* fixed the broken ramp\n",
    "* \"*We left iPad in a seat pocket.  Filed lost item report. Received it exactly 1 week Late Flightr.  Is that a record?  #unbelievable*\"\n",
    "\n",
    "However, this is not a significant problem since represents de 1% of the total tweets...\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "bg7BG1TnQt9Z",
    "outputId": "872a1419-e705-4744-ece2-9abda1c4ee8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@virginamerica Well, I didn't…but NOW I DO! :-D\n",
      "@VirginAmerica So excited for my first cross country flight LAX to MCO I've heard nothing but great things about Virgin America. #29DaysToGo\n",
      "@VirginAmerica come back to #PHL already. We need you to take us out of this horrible cold. #pleasecomeback http://t.co/gLXFwP6nQH\n",
      "@VirginAmerica twitter team. you guys killed it for rescheduling me asap. thank you!\n",
      "@united he has no priority and Iove it\n"
     ]
    }
   ],
   "source": [
    "for apos_pneg in df_wrong_tweets[\"apos_pneg\"][0:5]:\n",
    "  print(apos_pneg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvRtJznDEX9u"
   },
   "source": [
    "##### Error (2): *aneg_ppos*\n",
    "\n",
    "(ii) Tweets where the actual value is negative but Vader classified as positive:\n",
    "\n",
    "> **Red dots in the previous graph ubicated in y > 0** \n",
    "\n",
    "This is an important issue since 18% of total decisions using either the Textblob or Vader are made wrongly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cgn_Yzr-Ftx1"
   },
   "source": [
    "As we can observed in the printed tweeets from above, the TextBlob and Vader methods don't weight properly the words in the tweet. Let's take an example to understand what really is happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "yE3ol88RRsOz",
    "outputId": "468c6bb6-6021-40dc-f5b7-ab3d13604289"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica  I flew from NYC to SFO last week and couldn't fully sit in my seat due to two large gentleman on either side of me. HELP!\n",
      "@united Usually an issue with Express our of SFO. Positive note: Mainline p.s. was enjoyable.\n",
      "@VirginAmerica soooo are you guys going to leave the seatbelt light on all flight? You can barely call this turbulence :-)\n",
      "@VirginAmerica amazing to me that we can't get any cold air from the vents. #VX358 #noair #worstflightever #roasted #SFOtoBOS\n",
      "@VirginAmerica help, left expensive headphones on flight 89 IAD to LAX today. Seat 2A. No one answering L&amp;F number at LAX!\n"
     ]
    }
   ],
   "source": [
    "for aneg_ppos in df_wrong_tweets[\"aneg_ppos\"][0:5]:\n",
    "  print(aneg_ppos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "U5XWzDw4-Fhu",
    "outputId": "5e37ce1a-5b86-4fa5-b74d-42da9a972347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.1779\n",
      "1   -0.4824\n",
      "2    0.1062\n",
      "3   -0.5905\n",
      "Name: compound, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Understanding the problem of Hastags\n",
    "tweets_sample = (\"moved my seat with no notice. Better seat is cabin select not behind the row I selected👎 #DISAPPOINTED\",\n",
    "                 \"moved my seat with no notice. Better seat is cabin select not behind the row I selected👎 DISAPPOINTED\", \n",
    "                 \"why can't we book seats on your flights when we buy them or even during check in? Creates so much anxiety! #frustrated\",\n",
    "                 \"why can't we book seats on your flights when we buy them or even during check in? Creates so much anxiety! frustrated\")\n",
    "\n",
    "# Computing the Vader polarity when \"#\" is removed:\n",
    "print(sentiment_analysis(tweets_sample)[\"compound\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q67kToIXSuDi"
   },
   "source": [
    "##### Error (3): *aneu_ppos*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "sgC9cch2UioE",
    "outputId": "a6f6a0f4-6b0a-4270-cddf-1be601926072"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica Really missed a prime opportunity for Men Without Hats parody, there. https://t.co/mWpG7grEZP\n",
      "@VirginAmerica do you miss me? Don't worry we'll be together very soon.\n",
      "Nice RT @VirginAmerica: Vibe with the moodlight from takeoff to touchdown. #MoodlitMonday #ScienceBehindTheExperience http://t.co/Y7O0uNxTQP\n",
      "@VirginAmerica plz help me win my bid upgrade for my flight 2/27 LAX---&gt;SEA!!!  🍷👍💺✈️\n",
      "@VirginAmerica  DREAM http://t.co/oA2dRfAoQ2 http://t.co/lWWdAc2kHx\n"
     ]
    }
   ],
   "source": [
    "for aneu_ppos in df_wrong_tweets[\"aneu_ppos\"][0:5]:\n",
    "  print(aneu_ppos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EQBN2U1wTCTy"
   },
   "source": [
    "##### Error (4): *aneg_pneu*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "O22WGPYvUotG",
    "outputId": "a61a7139-fd98-459d-83d2-ec8601fa4b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica why are your first fares in May over three times more than other carriers when all seats are available to select???\n",
      "@VirginAmerica I called a 3-4 weeks ago about adding 3 flights from 2014 to my Elevate...they still haven't shown up...help!\n",
      "@VirginAmerica Hi, Virgin! I'm on hold for 40-50 minutes -- are there any earlier flights from LA to NYC tonight; earlier than 11:50pm?\n",
      "@virginamerica how's a direct flight FLL-&gt;SFO have unexpected layover in Vegas 4 fuel yet peeps next to me bought for Vegas flight. #sneaky\n",
      "@VirginAmerica I’m having trouble adding this flight my wife booked to my Elevate account. Help? http://t.co/pX8hQOKS3R\n"
     ]
    }
   ],
   "source": [
    "for aneg_pneu in df_wrong_tweets[\"aneg_pneu\"][0:5]:\n",
    "  print(aneg_pneu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5RGFzEufTHxn"
   },
   "source": [
    "##### Error (5): *apos_pneu*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "Ut8By_b2UugB",
    "outputId": "37773f0a-96d0-4789-abeb-7548f61e6076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica plus you've added commercials to the experience... tacky.\n",
      "@VirginAmerica @virginmedia I'm flying your #fabulous #Seductive skies again! U take all the #stress away from travel http://t.co/ahlXHhKiyn\n",
      "I ❤️ flying @VirginAmerica. ☺️👍\n",
      "@VirginAmerica View of downtown Los Angeles, the Hollywood Sign, and beyond that rain in the mountains! http://t.co/Dw5nf0ibtr\n",
      "@VirginAmerica you know it. Need it on my spotify stat #guiltypleasures\n"
     ]
    }
   ],
   "source": [
    "for apos_pneu in df_wrong_tweets[\"apos_pneu\"][0:5]:\n",
    "  print(apos_pneu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DhfiD2zmTNew"
   },
   "source": [
    "##### Error (6): *aneu_pneg*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "rEjnie2GU0_8",
    "outputId": "74eded3d-cbfe-4773-bc0d-f8149515424d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica will you be making BOS&gt;LAS non stop permanently anytime soon?\n",
      "@VirginAmerica LAX to EWR - Middle seat on a red eye. Such a noob maneuver. #sendambien #andchexmix\n",
      "@VirginAmerica Is flight 769 on it's way? Was supposed to take off 30 minutes ago. Website still shows \"On Time\" not \"In Flight\". Thanks.\n",
      "@VirginAmerica @LadyGaga @CarrieUnderwood Sorry, Mary Martin had it first!\n",
      "@VirginAmerica Flight 0736 DAL to DCA 2/24 2:10pm. Tried to check in could not. Status please.\n"
     ]
    }
   ],
   "source": [
    "for aneu_pneg in df_wrong_tweets[\"aneu_pneg\"][0:5]:\n",
    "  print(aneu_pneg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sYZM3LlmGyw1"
   },
   "source": [
    "The columns we need to focus are:\n",
    "-  `polarity` which is the sentiment analysis using Textblob.\n",
    "-  `compound` which is the sentiment analysis using Vader.\n",
    "\n",
    "The lecturer will have noticed that when we have a *hastag* both methods do not take into account the word - i.e. *disappointed* and *frustrated*\n",
    "\n",
    "This are one of the multiple problems that we want to solve. For that, in the next section we will try to apply the **N-GRAMS** approach. To do that, we need, first of all to tokenize the whole bunch of tweets.\n",
    "\n",
    "---\n",
    "TO DO: \n",
    "- Split hastags, specially the # with the word\n",
    "- Intesify words: joke, help, wait, delayed, luggage, suitcase, turbulence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GU_wp1pSWlSn"
   },
   "source": [
    "### 4) Reclassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEqarACYPeWA"
   },
   "source": [
    "Here an example where the first 200 tweets from the dataframe `tweets` are filtered.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gE2lWrfLTLKR"
   },
   "source": [
    "Having saw that now we want to increase the accuracy of TextBlob and Vader using the N-GRAMS. The **`ngrams`** function compute `bigrams = 2-grams` and `trigrams = 3-grams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X7OVViyQDmk1"
   },
   "outputs": [],
   "source": [
    "def ngrams(input_list):\n",
    "    #onegrams = input_list\n",
    "    bigrams = [' '.join(t) for t in list(zip(input_list, input_list[1:]))]\n",
    "    trigrams = [' '.join(t) for t in list(zip(input_list, input_list[1:], input_list[2:]))]\n",
    "    return bigrams + trigrams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SAqTuQsXHHt"
   },
   "source": [
    "Here an example with the apos_pneg tweets. We'll see that we improve 33% from our previous rate we had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtX3dib0FZaO"
   },
   "outputs": [],
   "source": [
    "# Before computing the ngrams function we need to tockenized the tweet\n",
    "apos_pneg_tockenized = tokenization_tweets(apos_pneg)\n",
    "apos_pneg_ngrams = []\n",
    "for tokens in apos_pneg_tockenized:\n",
    "  apos_pneg_ngrams.append(ngrams(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44dqZ1D8Fwj3"
   },
   "outputs": [],
   "source": [
    "# Then we join all the ngrams tockens as 1 string format\n",
    "apos_pneg_ngrams2 = []\n",
    "for tokens in apos_pneg_ngrams:\n",
    "  apos_pneg_ngrams2.append(' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2_7uXuguQhMh",
    "outputId": "6fb2f0a7-7ae3-4494-d3a3-e3ea321b7eef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks to N_GRAMS we reclassifies 0.00% of the total apos_pneg_ngrams well\n"
     ]
    }
   ],
   "source": [
    "# Finally we compute the sentiment_analysis using the string created before\n",
    "table = sentiment_analysis(apos_pneg_ngrams2)\n",
    "ratio_improved = sum(table[\"compound\"] > 0)/len(table[\"compound\"])\n",
    "print(\"Thanks to N_GRAMS we reclassifies {:.2%}\".format(ratio_improved) + \" of the total apos_pneg_ngrams well\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bcTKf30VQzrY"
   },
   "source": [
    "#### 4.1) Search group function\n",
    "\n",
    "The function **`search_group_classes`** allows the user to classify tweets by passangers classes:\n",
    "\n",
    "**Context**:\n",
    "From a business perspective, the company needs to prioritize which customer needs to be replied to firstly. The idea, is to create several classes and then sort based on priority. In the ideal world, this priority will be based on ticket price but this information cannot be inferred.\n",
    "\n",
    "- The first approach is to classify into 2 classes: **business class** and **not business class** only using the tweet text (i.e.: type of words in the tweet, orthography, etc.)\n",
    "\n",
    "- The second approach is to figure out what is the scope of the tweet. For instance, if the account is verified, or the complaint is made by a very popular account (with a lot of followers) the complaint needs to be dealt quickly. *(NOT IMPLEMENTED)*\n",
    "\n",
    "**Arguments**: \n",
    "*   `airline_sentiment`: determines the sentiment analysis we want to work with. Possible values: `('positive', 'negative', 'neutral')` \n",
    "*   `list_words`: words that define the group class, i.e.`(\"business class|first class|priority|preference\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zsovQdANHnPY"
   },
   "outputs": [],
   "source": [
    "def search_group_classes(airline_sentiment, list_words):\n",
    "    df_neg = (tweets[tweets['airline_sentiment'] == airline_sentiment])\n",
    "    list_tweets = df_neg[\"text\"]\n",
    "\n",
    "    output = []\n",
    "    for tweet in list_tweets:\n",
    "        if re.findall(list_words, tweet):\n",
    "            output.append(tweet)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEYoNaHqTZDy"
   },
   "source": [
    "Here we want to gathered the **business class tweets** from the dataset `tweets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "pt-Ra9dKTFQW",
    "outputId": "b37e3e97-c8d0-40bf-8422-1c584e0b68c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@VirginAmerica I need to register a service dog for a first class ticket from SFO &gt; Dulles. The phone queue is an hour or longer. Pls advise\n",
      "@united thanks ^mr i got rebooked already but I lost my first class seat. Such is life.\n",
      "@united only thing confusing me is why I lost priority boarding? I'm a mileage plus card member 😔\n",
      "@united three delayed flights and missed connections on first class flights and not get any compensation for losing those seats...\n",
      "@united - you rebooked me to UA1764 after UA 3883 was Cancelled Flightled. I paid for first class ticket - but new seat is 38E. Can you please fix!\n",
      "@united your first class is a joke, compared to all the others I have flown, don't ask for extra peanuts... That's NOT allowed! @AirCanada\n",
      "@united we've been seating for 5hrs inside flight UA936 at #IAD delayed. We've only been offered water &amp; cookies in business class. #failed\n",
      "@united can you make sure I’m on the upgrade list for 2/23 EWR-PDX using my GPU priority? Got a weird email about it.\n",
      "@united nope. Called, lost the seating preference I paid for, and here I still sit. We'll see what happens w/ my flight Late Flightr.\n",
      "@united hello I am flying first class and am behind 20 people on zone 1!!!!!  Pls pass on to app dept - you should board 1st class first\n"
     ]
    }
   ],
   "source": [
    "business_class = (\"business class|first class|priority|preference\") # TO DO: store it in the tweets dataframe\n",
    "business_class_tweets = search_group_classes(\"negative\", business_class)\n",
    "for bc_tweet in business_class_tweets[0:10]:\n",
    "    print(bc_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kPDCbj3tbgrd"
   },
   "source": [
    "### 5) Train, test and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xUEul5swb7Es"
   },
   "source": [
    "### 6) Model validation\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4amsSXiZDQF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GESw7PFKcD1V"
   },
   "source": [
    "### 7) Business model\n",
    "Sorting the tweets that have to be replied firstly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qiHUaQX1WBRi"
   },
   "source": [
    "### 8) The sentiment methods used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iCPMGSiqyPw_"
   },
   "source": [
    "#### 8.1) Vader\n",
    "**V**alence **A**ware **D**ictionary and s**E**ntiment **R**easoner is another popular rule-based library for sentiment analysis. Like TextBlob, it uses a sentiment lexicon that contains intensity measures for each word based on human-annotated labels. A key difference however, is that VADER was designed with a **focus on social media texts**. This means that it puts a lot of emphasis on rules that capture the essence of text typically seen on social media — for example, **short sentences with emojis**, **repetitive vocabulary** and copious use of **punctuation** (such as exclamation marks). Below are some examples of the sentiment intensity scores output by VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "nSDbVwI7vL5b",
    "outputId": "e47b7362-fc8b-42ae-c961-bf67d6e37875"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neg': 0.0, 'neu': 0.682, 'pos': 0.318, 'compound': 0.6369}\n",
      "{'neg': 0.0, 'neu': 0.323, 'pos': 0.677, 'compound': 0.6369}\n",
      "{'neg': 0.0, 'neu': 0.646, 'pos': 0.354, 'compound': 0.7125}\n",
      "{'neg': 0.0, 'neu': 0.633, 'pos': 0.367, 'compound': 0.7371}\n",
      "{'neg': 0.0, 'neu': 0.608, 'pos': 0.392, 'compound': 0.7788}\n",
      "{'neg': 0.0, 'neu': 0.324, 'pos': 0.676, 'compound': 0.9675}\n",
      "{'neg': 0.645, 'neu': 0.355, 'pos': 0.0, 'compound': -0.9541}\n"
     ]
    }
   ],
   "source": [
    "vader = SentimentIntensityAnalyzer()\n",
    "print(vader.polarity_scores(\"This was the best idea I've had in a long time.\"))\n",
    "print(vader.polarity_scores(\"best idea time.\"))\n",
    "print(vader.polarity_scores(\"This was the BEST idea I've had in a long time.\"))\n",
    "print(vader.polarity_scores(\"This was the BEST idea I've had in a long time!\"))\n",
    "print(vader.polarity_scores(\"This was the BEST idea I've had in a long time!!!\"))\n",
    "print(vader.polarity_scores(\"This was the BEST, BEST idea I've had in a long time!!! :D :D\"))\n",
    "print(vader.polarity_scores(\"This was the WORST, WORST idea I've had in a long time!!! :( :(\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xfSDDK7vVest"
   },
   "source": [
    "#### 8.2) TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "z81Av1m71zLo",
    "outputId": "a94a0f05-fe0a-4c74-e840-f2d31a18aa78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.475, subjectivity=0.35)\n",
      "Sentiment(polarity=1.0, subjectivity=0.3)\n",
      "Sentiment(polarity=0.475, subjectivity=0.35)\n",
      "Sentiment(polarity=0.46875, subjectivity=0.35)\n",
      "Sentiment(polarity=0.451171875, subjectivity=0.35)\n",
      "Sentiment(polarity=0.78046875, subjectivity=0.6)\n",
      "Sentiment(polarity=-0.71953125, subjectivity=0.8800000000000001)\n"
     ]
    }
   ],
   "source": [
    "print(TextBlob(\"This was the best idea I've had in a long time.\").sentiment)\n",
    "print(TextBlob(\"best idea time.\").sentiment)\n",
    "print(TextBlob(\"This was the BEST idea I've had in a long time.\").sentiment)\n",
    "print(TextBlob(\"This was the BEST idea I've had in a long time!\").sentiment)\n",
    "print(TextBlob(\"This was the BEST idea I've had in a long time!!!\").sentiment)\n",
    "print(TextBlob(\"This was the BEST, BEST idea I've had in a long time!!! :D :D\").sentiment)\n",
    "print(TextBlob(\"This was the WORST, WORST idea I've had in a long time!!! :( :(\").sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YPEzAjOkW4cK"
   },
   "source": [
    "## Tweet translation\n",
    "We can imagine that airlines might have different customer support teams spead in different localizations. We can detect the language of the tweets posted and hence transfer them to the correct team. Otherwise, translating the tweets will allow any support team to understand the tweets. Also, if the tweets were in different languages it can make sense to translate them into English or any desired language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xPUJNXDbW4cK",
    "outputId": "18d6c252-98a1-4d8d-9ce4-b95d8b058971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en']\n"
     ]
    }
   ],
   "source": [
    "#Detect languange\n",
    "list_language = []\n",
    "tweet_for_language = tweets[\"text\"]\n",
    "for element in tweet_for_language[:10]:\n",
    "    which_language = TextBlob(element)\n",
    "    which_language.detect_language()#Detect the blob's language using the Google Translate API.\n",
    "    list_language.append(which_language.detect_language())\n",
    "print(list_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "294pjhf7W4cN",
    "outputId": "5b5bc88e-c44c-4e91-d26a-71ac7d4a0f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@VirginAmerica Lo que dijo @dhepburn.', '@VirginAmerica plus has agregado comerciales a la experiencia ... de mal gusto.', '@VirginAmerica es realmente agresivo lanzar \"entretenimiento\" desagradable en las caras de tus invitados & amp; tienen poco recurso', '@VirginAmerica y es algo realmente malo', '@VirginAmerica seriamente pagaría $ 30 por vuelo por asientos que no tenían este juego.\\nes realmente lo único malo de volar VA', '@VirginAmerica No lo hice hoy ... ¡Debe significar que necesito hacer otro viaje!', '@VirginAmerica sí, casi cada vez que vuelo en VX este \"gusano del oído\" no desaparecerá :)', '@VirginAmerica Realmente perdí una oportunidad privilegiada para la parodia de Hombres sin Sombreros, allí. https://t.co/mWpG7grEZP', '@virginamerica Bueno, no lo hice ... ¡pero AHORA LO HAGO! :-RE', '@VirginAmerica fue increíble y llegó una hora antes. Eres muy bueno conmigo']\n"
     ]
    }
   ],
   "source": [
    "#Translation\n",
    "list_translations = []\n",
    "for element in tweet_for_language[:10]:\n",
    "    text_to_be_translated = TextBlob(element)\n",
    "    text_to_be_translated.translate(to ='es')#Translates the blob to another language using the Google Translate API.\n",
    "    list_translations.append(str(text_to_be_translated.translate(to ='es')))\n",
    "print(list_translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "colab_type": "code",
    "id": "3GcCXhY-W4cO",
    "outputId": "28b8f5a5-f3d5-46bc-cb1a-510975947c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  ...                                 translation_tweets\n",
      "0           0  ...              @VirginAmerica Lo que dijo @dhepburn.\n",
      "1           1  ...  @VirginAmerica plus has agregado comerciales a...\n",
      "2           2  ...  @VirginAmerica es realmente agresivo lanzar \"e...\n",
      "3           3  ...            @VirginAmerica y es algo realmente malo\n",
      "4           4  ...  @VirginAmerica seriamente pagaría $ 30 por vue...\n",
      "5           5  ...  @VirginAmerica No lo hice hoy ... ¡Debe signif...\n",
      "6           6  ...  @VirginAmerica sí, casi cada vez que vuelo en ...\n",
      "7           7  ...  @VirginAmerica Realmente perdí una oportunidad...\n",
      "8           8  ...  @virginamerica Bueno, no lo hice ... ¡pero AHO...\n",
      "9           9  ...  @VirginAmerica fue increíble y llegó una hora ...\n",
      "\n",
      "[10 rows x 26 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#Adding language and translation to tweets table\n",
    "table_10_lines = tweets[:10]\n",
    "table_10_lines[\"language_tweets\"] = list_language\n",
    "table_10_lines[\"translation_tweets\"] = list_translations\n",
    "print(table_10_lines)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
